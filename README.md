# US-Top-Companies-Web-Scraper
Project Overview

This project demonstrates an end-to-end web scraping workflow using Python, focusing on extracting structured business data from unstructured web content. The dataset is sourced from Wikipedia and contains information on the largest U.S. companies by revenue.

The project emphasizes:

Responsible and ethical web scraping practices

Clear, reproducible data pipelines

Transformation of raw HTML into clean, analysis-ready data

ğŸ› ï¸ Tools & Technologies

Python

Requests â€“ for sending HTTP requests

BeautifulSoup (bs4) â€“ for parsing HTML content

Pandas â€“ for data cleaning and tabular structuring

CSV â€“ for exporting data in an analysis-ready format

ğŸ”„ Workflow

Data Source Identification

Wikipedia page listing the largest U.S. companies by revenue

Web Request Handling

Fetching HTML content using the requests library

HTML Parsing & Extraction

Parsing tables with BeautifulSoup

Extracting relevant fields (e.g., company name, revenue, industry, rank)

Data Cleaning & Structuring

Converting raw scraped data into a clean Pandas DataFrame

Handling inconsistencies and formatting issues

Data Export

Saving the final dataset as a CSV file ready for analysis or visualization

ğŸ“‚ Project Structure
MySQL_Data_Cleaning_Project/
â”‚
â”œâ”€â”€ scraper.py              # Main web scraping script
â”œâ”€â”€ companies.csv           # Cleaned dataset (output)
â”œâ”€â”€ requirements.txt        # Project dependencies
â””â”€â”€ README.md               # Project documentation

ğŸ“Š Output

A clean CSV dataset containing structured information on major U.S. companies by revenue

Ready for use in:

Exploratory Data Analysis (EDA)

SQL databases

Business intelligence dashboards

Machine learning pipelines

âš–ï¸ Ethical Considerations

Data was scraped from a publicly accessible Wikipedia page

No aggressive requests or bypassing of protections

Intended strictly for educational and analytical purposes

ğŸš€ Possible Extensions

Automate updates using scheduled scripts

Store scraped data in a SQL database

Perform trend analysis and visualizations

Extend scraping to global company rankings

ğŸ‘¤ Author

Tim
Data Analyst | Data Scientist (in training)
Passionate about building transparent, reproducible data pipelines and real-world analytics solutions.
